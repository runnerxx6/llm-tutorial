{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 这是一个注释","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U transformers","metadata":{"colab_type":"code","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import snapshot_download\nlocal_dir = \"/kaggle/working\"\nsnapshot_download(repo_id=\"Qwen/Qwen3-0.6B\", local_dir=\"/kaggle/working/Qwen/Qwen3-0.6B\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use a pipeline as a high-level helper\nfrom transformers import pipeline\n\npipe = pipeline(\"text-generation\", model=\"Qwen/Qwen3-0.6B\")\nmessages = [\n    {\"role\": \"user\", \"content\": \"Who are you?\"},\n]\npipe(messages)","metadata":{"colab_type":"code","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"/kaggle/working/Qwen/Qwen3-0.6B\"\ntokenizer = AutoTokenizer.from_pretrained(model_name )\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    dtype=\"auto\",\n    device_map=\"auto\" \n)","metadata":{"colab_type":"code","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\nmessages = [\n    {\"role\": \"user\", \"content\": \"你是谁呀？\"},\n]\ninputs = tokenizer.apply_chat_template(\n\tmessages,\n\tadd_generation_prompt=True,\n\ttokenize=True,\n    return_dict=True,\n\treturn_tensors=\"pt\",\n    enable_thinking=True\n).to(model.device)\n\nprint(inputs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TextStreamer","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"outputs = model.generate(**inputs, max_new_tokens=1024)\nprint(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\nmodel.generate(**inputs, max_new_tokens=1024, streamer=streamer)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}